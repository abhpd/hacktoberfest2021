{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "############## TENSORBOARD ########################\r\n",
    "import sys\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\r\n",
    "writer = SummaryWriter('runs/mnist1')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files (x86)\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Hyper-parameters \r\n",
    "input_size = 784 # 28x28\r\n",
    "hidden_size = 500 \r\n",
    "num_classes = 10\r\n",
    "num_epochs = 1\r\n",
    "batch_size = 64\r\n",
    "learning_rate = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# MNIST dataset \r\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \r\n",
    "                                           train=True, \r\n",
    "                                           transform=transforms.ToTensor(),  \r\n",
    "                                           download=False)\r\n",
    "\r\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \r\n",
    "                                          train=False, \r\n",
    "                                          transform=transforms.ToTensor())\r\n",
    "\r\n",
    "# Data loader\r\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
    "                                           batch_size=batch_size, \r\n",
    "                                           shuffle=True)\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
    "                                          batch_size=batch_size, \r\n",
    "                                          shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "examples = iter(test_loader)\r\n",
    "example_data, example_targets = examples.next()\r\n",
    "\r\n",
    "for i in range(6):\r\n",
    "    plt.subplot(2,3,i+1)\r\n",
    "    plt.imshow(example_data[i][0], cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "img_grid = torchvision.utils.make_grid(example_data)\r\n",
    "writer.add_image('mnist_images', img_grid)\r\n",
    "# writer.close()\r\n",
    "# sys.exit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Fully connected neural network with one hidden layer\r\n",
    "class NeuralNet(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\r\n",
    "        super(NeuralNet, self).__init__()\r\n",
    "        self.input_size = input_size\r\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.l1(x)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.l2(out)\r\n",
    "        # no activation and no softmax at the end\r\n",
    "        return out\r\n",
    "\r\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Loss and optimizer\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \r\n",
    "\r\n",
    "############## TENSORBOARD ########################\r\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\r\n",
    "writer.close()\r\n",
    "sys.exit"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function sys.exit(status=None, /)>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Train the model\r\n",
    "running_loss = 0.0\r\n",
    "running_correct = 0\r\n",
    "n_total_steps = len(train_loader)\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):  \r\n",
    "        # origin shape: [100, 1, 28, 28]\r\n",
    "        # resized: [100, 784]\r\n",
    "        images = images.reshape(-1, 28*28)\r\n",
    "        labels = labels\r\n",
    "        \r\n",
    "        # Forward pass\r\n",
    "        outputs = model(images)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "        \r\n",
    "        # Backward and optimize\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "        running_correct += (predicted == labels).sum().item()\r\n",
    "        if (i+1) % 100 == 0:\r\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\r\n",
    "            ############## TENSORBOARD ########################\r\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\r\n",
    "            running_accuracy = running_correct / 100 / predicted.size(0)\r\n",
    "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\r\n",
    "            running_correct = 0\r\n",
    "            running_loss = 0.0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/1], Step [100/938], Loss: 0.3955\n",
      "Epoch [1/1], Step [200/938], Loss: 0.2594\n",
      "Epoch [1/1], Step [300/938], Loss: 0.3812\n",
      "Epoch [1/1], Step [400/938], Loss: 0.2772\n",
      "Epoch [1/1], Step [500/938], Loss: 0.2385\n",
      "Epoch [1/1], Step [600/938], Loss: 0.1105\n",
      "Epoch [1/1], Step [700/938], Loss: 0.1954\n",
      "Epoch [1/1], Step [800/938], Loss: 0.1467\n",
      "Epoch [1/1], Step [900/938], Loss: 0.1190\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Test the model\r\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\r\n",
    "class_labels = []\r\n",
    "class_preds = []\r\n",
    "with torch.no_grad():\r\n",
    "    n_correct = 0\r\n",
    "    n_samples = 0\r\n",
    "    for images, labels in test_loader:\r\n",
    "        images = images.reshape(-1, 28*28)\r\n",
    "        labels = labels\r\n",
    "        outputs = model(images)\r\n",
    "        # max returns (value ,index)\r\n",
    "        values, predicted = torch.max(outputs.data, 1)\r\n",
    "        n_samples += labels.size(0)\r\n",
    "        n_correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\r\n",
    "\r\n",
    "        class_preds.append(class_probs_batch)\r\n",
    "        class_labels.append(predicted)\r\n",
    "\r\n",
    "    # 10000, 10, and 10000, 1\r\n",
    "    # stack concatenates tensors along a new dimension\r\n",
    "    # cat concatenates tensors in the given dimension\r\n",
    "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\r\n",
    "    class_labels = torch.cat(class_labels)\r\n",
    "\r\n",
    "    acc = 100.0 * n_correct / n_samples\r\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\r\n",
    "\r\n",
    "    ############## TENSORBOARD ########################\r\n",
    "    classes = range(10)\r\n",
    "    for i in classes:\r\n",
    "        labels_i = class_labels == i\r\n",
    "        preds_i = class_preds[:, i]\r\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\r\n",
    "        writer.close()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.22 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "b8d0ede588d15b89434cd61d7894b7bb4dbe752a5f2a1bd905f19276a50935ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}